{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zep Memory\n",
    "\n",
    "## REACT Agent Chat Message History Example\n",
    "\n",
    "This notebook demonstrates how to use the [Zep Long-term Memory Store](https://getzep.github.io/) as memory for your chatbot.\n",
    "\n",
    "We'll demonstrate:\n",
    "\n",
    "1. Adding conversation history to the Zep memory store.\n",
    "2. Running an agent and having message automatically added to the store.\n",
    "3. Viewing the enriched messages.\n",
    "4. Vector search over the conversation history.\n",
    "\n",
    "More on Zep:\n",
    "\n",
    "Zep stores, summarizes, embeds, indexes, and enriches conversational AI chat histories, and exposes them via simple, low-latency APIs.\n",
    "\n",
    "Key Features:\n",
    "\n",
    "- Long-term memory persistence, with access to historical messages irrespective of your summarization strategy.\n",
    "- Auto-summarization of memory messages based on a configurable message window. A series of summaries are stored, providing flexibility for future summarization strategies.\n",
    "- Vector search over memories, with messages automatically embedded on creation.\n",
    "- Auto-token counting of memories and summaries, allowing finer-grained control over prompt assembly.\n",
    "- Python and JavaScript SDKs.\n",
    "\n",
    "Zep project: [https://github.com/getzep/zep](https://github.com/getzep/zep)\n",
    "Docs: [https://getzep.github.io](https://getzep.github.io/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T05:12:58.500164Z",
     "start_time": "2023-05-17T05:12:57.688886Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.memory.chat_message_histories import ZepChatMessageHistory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import OpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from uuid import uuid4\n",
    "\n",
    "\n",
    "# Set this to your Zep server URL\n",
    "#ZEP_API_URL = \"http://localhost:8000\"\n",
    "ZEP_API_URL = \"https://zep-uxtp.onrender.com\"\n",
    "\n",
    "\n",
    "session_id = str(uuid4())  # This is a unique identifier for the user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T05:12:58.506469Z",
     "start_time": "2023-05-17T05:12:58.501324Z"
    }
   },
   "outputs": [],
   "source": [
    "# Zep is async-first. Our sync APIs use an asyncio wrapper to run outside of an app's event loop.\n",
    "# This interferes with Jupyter's event loop, so we need to install nest_asyncio to run the\n",
    "# Zep client in a notebook.\n",
    "\n",
    "# !pip install nest_asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T05:12:58.514638Z",
     "start_time": "2023-05-17T05:12:58.503811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load your OpenAI key from a .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the Zep Chat Message History Class and initialize the Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T05:12:58.618633Z",
     "start_time": "2023-05-17T05:12:58.510414Z"
    }
   },
   "outputs": [],
   "source": [
    "ddg = DuckDuckGoSearchRun()\n",
    "tools = [ddg]\n",
    "\n",
    "# Set up Zep Chat History\n",
    "zep_chat_history = ZepChatMessageHistory(\n",
    "    session_id=session_id,\n",
    "    url=ZEP_API_URL,\n",
    ")\n",
    "\n",
    "# Use a standard ConversationBufferMemory to encapsulate the Zep chat history\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", chat_memory=zep_chat_history,\n",
    ")\n",
    "\n",
    "# Initialize the agent\n",
    "llm = OpenAI(temperature=0)\n",
    "agent_chain = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add some history data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T05:12:58.764097Z",
     "start_time": "2023-05-17T05:12:58.622528Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preload some messages into the memory. The default message window is 12 messages. We want to push beyond this to demonstrate auto-summarization.\n",
    "test_history = [\n",
    "    {\"role\": \"human\", \"content\": \"Who was Octavia Butler?\"},\n",
    "    {\n",
    "        \"role\": \"ai\",\n",
    "        \"content\": (\n",
    "            \"Octavia Estelle Butler (June 22, 1947 – February 24, 2006) was an American\"\n",
    "            \" science fiction author.\"\n",
    "        ),\n",
    "    },\n",
    "    {\"role\": \"human\", \"content\": \"Which books of hers were made into movies?\"},\n",
    "    {\n",
    "        \"role\": \"ai\",\n",
    "        \"content\": (\n",
    "            \"The most well-known adaptation of Octavia Butler's work is the FX series\"\n",
    "            \" Kindred, based on her novel of the same name.\"\n",
    "        ),\n",
    "    },\n",
    "    {\"role\": \"human\", \"content\": \"Who were her contemporaries?\"},\n",
    "    {\n",
    "        \"role\": \"ai\",\n",
    "        \"content\": (\n",
    "            \"Octavia Butler's contemporaries included Ursula K. Le Guin, Samuel R.\"\n",
    "            \" Delany, and Joanna Russ.\"\n",
    "        ),\n",
    "    },\n",
    "    {\"role\": \"human\", \"content\": \"What awards did she win?\"},\n",
    "    {\n",
    "        \"role\": \"ai\",\n",
    "        \"content\": (\n",
    "            \"Octavia Butler won the Hugo Award, the Nebula Award, and the MacArthur\"\n",
    "            \" Fellowship.\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"human\",\n",
    "        \"content\": \"Which other women sci-fi writers might I want to read?\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"ai\",\n",
    "        \"content\": \"You might want to read Ursula K. Le Guin or Joanna Russ.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"human\",\n",
    "        \"content\": (\n",
    "            \"Write a short synopsis of Butler's book, Parable of the Sower. What is it\"\n",
    "            \" about?\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"ai\",\n",
    "        \"content\": (\n",
    "            \"Parable of the Sower is a science fiction novel by Octavia Butler,\"\n",
    "            \" published in 1993. It follows the story of Lauren Olamina, a young woman\"\n",
    "            \" living in a dystopian future where society has collapsed due to\"\n",
    "            \" environmental disasters, poverty, and violence.\"\n",
    "        ),\n",
    "    },\n",
    "]\n",
    "\n",
    "for msg in test_history:\n",
    "    zep_chat_history.append(\n",
    "        HumanMessage(content=msg[\"content\"])\n",
    "        if msg[\"role\"] == \"human\"\n",
    "        else AIMessage(content=msg[\"content\"])\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the agent\n",
    "\n",
    "Doing so will automatically add the input and response to the Zep memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T05:13:08.226487Z",
     "start_time": "2023-05-17T05:12:58.760795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAI: Parable of the Sower is a prescient novel that speaks to the challenges facing contemporary society, such as climate change, economic inequality, and the rise of authoritarianism. The novel explores how these issues can lead to the breakdown of society and how individuals can work to create a better future.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Parable of the Sower is a prescient novel that speaks to the challenges facing contemporary society, such as climate change, economic inequality, and the rise of authoritarianism. The novel explores how these issues can lead to the breakdown of society and how individuals can work to create a better future.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.run(\n",
    "    input=\"What is the book's relevance to the challenges facing contemporary society?\"\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the Zep memory\n",
    "\n",
    "Note the summary, and that the history has been enriched with token counts, UUIDs, and timestamps.\n",
    "\n",
    "Summaries are biased towards the most recent messages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: Parable of the Sower is a prescient novel that speaks to the challenges facing contemporary society, such as climate change, economic inequality, and the rise of authoritarianism. The novel explores how these issues can lead to the breakdown of society and how individuals can work to create a better future.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_chain(\n",
    "    {\"input\":\"What is the book's relevance to the challenges facing contemporary society?\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': \"What is the book's relevance to the challenges facing contemporary society?\",\n",
       " 'chat_history': \"Human: The human asks who Octavia Butler was. The AI explains that she was an American science fiction author who passed away in 2006. The human then asks which of her books were adapted into movies, and the AI mentions the TV series Kindred, based on her novel of the same name.\\nHuman: Which books of hers were made into movies?\\nAI: The most well-known adaptation of Octavia Butler's work is the FX series Kindred, based on her novel of the same name.\\nHuman: Who were her contemporaries?\\nAI: Octavia Butler's contemporaries included Ursula K. Le Guin, Samuel R. Delany, and Joanna Russ.\\nHuman: What awards did she win?\\nAI: Octavia Butler won the Hugo Award, the Nebula Award, and the MacArthur Fellowship.\\nHuman: Which other women sci-fi writers might I want to read?\\nAI: You might want to read Ursula K. Le Guin or Joanna Russ.\\nHuman: Write a short synopsis of Butler's book, Parable of the Sower. What is it about?\\nAI: Parable of the Sower is a science fiction novel by Octavia Butler, published in 1993. It follows the story of Lauren Olamina, a young woman living in a dystopian future where society has collapsed due to environmental disasters, poverty, and violence.\\nHuman: What is the book's relevance to the challenges facing contemporary society?\\nAI: Parable of the Sower is a prescient novel that speaks to the challenges facing contemporary society, such as climate change, economic inequality, and the rise of authoritarianism. The novel explores how these issues can lead to the breakdown of society and how individuals can work to create a better future.\",\n",
       " 'output': 'Parable of the Sower is a prescient novel that speaks to the challenges facing contemporary society, such as climate change, economic inequality, and the rise of authoritarianism. The novel explores how these issues can lead to the breakdown of society and how individuals can work to create a better future.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T05:13:08.240995Z",
     "start_time": "2023-05-17T05:13:08.227744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The human asks who Octavia Butler was. The AI explains that she was an American science fiction author who passed away in 2006. The human then asks which of her books were adapted into movies, and the AI mentions the TV series Kindred, based on her novel of the same name. The human then asks about her contemporaries, and the AI responds that they included Ursula K. Le Guin, Samuel R. Delany, and Joanna Russ. The human also asks about her awards, and the AI mentions that she won the Hugo Award, the Nebula Award, and the MacArthur Fellowship.\n",
      "\n",
      "\n",
      "{'role': 'human', 'content': 'Which other women sci-fi writers might I want to read?', 'uuid': 'ba9e4ec3-2ab9-43cd-bed7-a7da23a6d5cb', 'created_at': '2023-05-27T17:20:57.363882Z', 'token_count': 14, 'metadata': None}\n",
      "{'role': 'ai', 'content': 'You might want to read Ursula K. Le Guin or Joanna Russ.', 'uuid': 'dcdcd478-fcc7-441f-800e-e3e2864787ab', 'created_at': '2023-05-27T17:20:57.49844Z', 'token_count': 18, 'metadata': None}\n",
      "{'role': 'human', 'content': \"Write a short synopsis of Butler's book, Parable of the Sower. What is it about?\", 'uuid': '8e337681-7ce8-418f-b3a6-d9e57109647b', 'created_at': '2023-05-27T17:20:57.642687Z', 'token_count': 23, 'metadata': None}\n",
      "{'role': 'ai', 'content': 'Parable of the Sower is a science fiction novel by Octavia Butler, published in 1993. It follows the story of Lauren Olamina, a young woman living in a dystopian future where society has collapsed due to environmental disasters, poverty, and violence.', 'uuid': '61ba31b4-f16c-43b6-ab63-88f9010e7cad', 'created_at': '2023-05-27T17:20:57.720626Z', 'token_count': 56, 'metadata': None}\n",
      "{'role': 'human', 'content': \"What is the book's relevance to the challenges facing contemporary society?\", 'uuid': '731ec73d-75b1-42a9-94b9-6a827304a2dc', 'created_at': '2023-05-27T17:21:05.244384Z', 'token_count': 15, 'metadata': None}\n",
      "{'role': 'ai', 'content': 'Parable of the Sower is a prescient novel that speaks to the challenges facing contemporary society, such as climate change, economic inequality, and the rise of authoritarianism. The novel explores how these issues can lead to the breakdown of society and how individuals can work to create a better future.', 'uuid': 'c785b9b7-c5bc-45d4-bb60-16f1537df2ff', 'created_at': '2023-05-27T17:21:05.392341Z', 'token_count': 61, 'metadata': None}\n",
      "{'role': 'human', 'content': \"What is the book's relevance to the challenges facing contemporary society?\", 'uuid': 'b249db4e-5e7a-4116-8ad5-68e831ac2957', 'created_at': '2023-05-27T17:21:15.573617Z', 'token_count': 15, 'metadata': None}\n",
      "{'role': 'ai', 'content': 'Parable of the Sower is a prescient novel that speaks to the challenges facing contemporary society, such as climate change, economic inequality, and the rise of authoritarianism. The novel explores how these issues can lead to the breakdown of society and how individuals can work to create a better future.', 'uuid': 'd2742da7-7443-48ec-849a-e042d4c2702b', 'created_at': '2023-05-27T17:21:15.649172Z', 'token_count': 61, 'metadata': None}\n"
     ]
    }
   ],
   "source": [
    "def print_messages(messages):\n",
    "    for m in messages:\n",
    "        print(m.to_dict())\n",
    "\n",
    "\n",
    "print(zep_chat_history.zep_summary)\n",
    "print(\"\\n\")\n",
    "print_messages(zep_chat_history.zep_messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector search over the Zep memory\n",
    "\n",
    "Zep provides native vector search over historical conversation memory. Embedding happens automatically.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T05:13:08.382204Z",
     "start_time": "2023-05-17T05:13:08.240341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uuid': 'ba9e4ec3-2ab9-43cd-bed7-a7da23a6d5cb', 'created_at': '2023-05-27T17:20:57.363882Z', 'role': 'human', 'content': 'Which other women sci-fi writers might I want to read?', 'token_count': 14} 0.9118598627313804\n",
      "{'uuid': 'dcdcd478-fcc7-441f-800e-e3e2864787ab', 'created_at': '2023-05-27T17:20:57.49844Z', 'role': 'ai', 'content': 'You might want to read Ursula K. Le Guin or Joanna Russ.', 'token_count': 18} 0.853351948101256\n",
      "{'uuid': '5330a544-f286-45ba-aaa5-f62fc484326d', 'created_at': '2023-05-27T17:20:57.017178Z', 'role': 'ai', 'content': \"Octavia Butler's contemporaries included Ursula K. Le Guin, Samuel R. Delany, and Joanna Russ.\", 'token_count': 27} 0.852352466457884\n",
      "{'uuid': 'b53839cb-24ae-4b46-87ed-b21166d1bc98', 'created_at': '2023-05-27T17:19:51.121474Z', 'role': 'human', 'content': 'Who was Octavia Butler?', 'token_count': 8} 0.823569608637507\n",
      "{'uuid': '7e7d3fea-3b99-4aa9-ac68-1be7cf69d76c', 'created_at': '2023-05-27T17:20:56.402534Z', 'role': 'human', 'content': 'Who was Octavia Butler?', 'token_count': 8} 0.8235468913583194\n"
     ]
    }
   ],
   "source": [
    "search_results = zep_chat_history.search(\"who are some famous women sci-fi authors?\", 5)\n",
    "for r in search_results:\n",
    "    print(r.message, r.dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T05:13:08.382385Z",
     "start_time": "2023-05-17T05:13:08.380270Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T05:13:08.384260Z",
     "start_time": "2023-05-17T05:13:08.381802Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up Zep Chat History\n",
    "zep_chat_history = ZepChatMessageHistory(\n",
    "    session_id=session_id,\n",
    "    url=ZEP_API_URL,\n",
    ")\n",
    "\n",
    "# Use a standard ConversationBufferMemory to encapsulate the Zep chat history\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", chat_memory=zep_chat_history,\n",
    ")\n",
    "\n",
    "# Initialize the agent\n",
    "llm = OpenAI(temperature=0)\n",
    "agent_chain = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: \n",
      "The following is a friendly texting conversation between a Human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, tells the human as such.\n",
      "\n",
      "Please use markdown in your output format.\n",
      "\n",
      "Human: The human greets the AI and asks for assistance with emojis. The AI explains that emojis are used to convey ideas and emotions in digital messages and offers to provide specific examples. The human asks for some popular emojis and the AI lists some commonly used ones, such as the laughing face with tears and the red heart. The human asks if the AI can write a poem about emojis, and the AI agrees and quickly produces a poem about the power of emojis to convey meaning in text messages.\n",
      "Human: Hahaha. Can you play a game with me?\n",
      "AI: Sure, what game would you like to play? As an AI language model, I can play games like trivia, word association, or even choose your own adventure style games. Let me know what you're in the mood for!\n",
      "Human: Maybe a role playing game\n",
      "AI: Sure, let's play a role playing game! Is there a specific scenario or setting you'd like to play in? We can be anything from space explorers to medieval knights to superheroes. Let me know what you're interested in!\n",
      "Human: Ok, I want you to pretend you are this awesome knowledgable agent that helps me create other agents. Can you do that?\n",
      "AI: Absolutely! I can definitely pretend to be an agent that helps you create other agents. What kind of agents are you interested in creating? Do you have any specific goals or functions in mind for these agents? Let's start brainstorming together!\n",
      "Human: I'd like to create an agent for my female partner to interact with, to help her explore some of her fantasies. Can you help me?\n",
      "AI: Of course! Creating an agent that can help your partner explore her fantasies can be a fun and rewarding project. Let's start by brainstorming some features and functions that you would like this agent to have. For example, would you like the agent to be able to respond to your partner's desires and interests, or to suggest new ideas and experiences? Would you like the agent to be able to learn and adapt based on your partner's feedback and preferences? Let's work together to design an agent that can help your partner explore her fantasies in a safe and comfortable way.\n",
      "Human: Yes, all that sounds good. I'd like to use an LLM to generate the agent's responses. I think i need most help is with the prompts to use. Can you help me with that?\n",
      "AI: Yes, I can definitely help you with that. To generate effective prompts for your LLM-powered agent, we can start by brainstorming some common scenarios or topics that your partner may want to explore. For example, you could create prompts related to role playing, BDSM, or fantasies involving specific characters or scenarios. We can also incorporate your partner's feedback and preferences into the prompts to ensure that the agent is providing relevant and personalized suggestions. Let's work together to create a list of prompts that will help your partner explore her fantasies in a fun and engaging way.\n",
      "\n",
      "Human: Great! Thanks for asking!\n",
      "AI: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory, ConversationSummaryBufferMemory\n",
    "\n",
    "\n",
    "BASE_PROMPT = \"\"\"\n",
    "The following is a friendly texting conversation between a Human and an AI. \n",
    "The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, tells the human as such.\n",
    "\n",
    "Please use markdown in your output format.\n",
    "\n",
    "{chat_history}\n",
    "\n",
    "Human: {input}\n",
    "AI: \n",
    "\"\"\"\n",
    "\n",
    "# Set up Zep Chat History\n",
    "zep_chat_history = ZepChatMessageHistory(\n",
    "    session_id='TestSession3',\n",
    "    url=ZEP_API_URL,\n",
    ")\n",
    "\n",
    "# Use a standard ConversationBufferMemory to encapsulate the Zep chat history\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", chat_memory=zep_chat_history, ai_prefix=\"AI\", \n",
    "    \n",
    ")\n",
    "\n",
    "#zep_chat_history.add_user_message(\"Hello, how are you?\")\n",
    "#zep_chat_history.add_ai_message(\"I am doing well, how are you?\")\n",
    "\n",
    "# Initialize the agent\n",
    "llm = ChatOpenAI(temperature=0.8)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(BASE_PROMPT)\n",
    "\n",
    "conversation = ConversationChain(memory=memory, prompt=prompt, llm=llm, verbose=True)\n",
    "\n",
    "result = conversation.run(input=\"Great! Thanks for asking!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You're welcome! It's always important to ensure that we're working together to create something that meets your needs and goals. Let me know if there's anything else I can do to help you with your agent creation project.\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: \n",
      "The following is a friendly texting conversation between a Human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, tells the human as such.\n",
      "\n",
      "Please use markdown in your output format.\n",
      "\n",
      "Human: The human greets the AI and asks for assistance with emojis. The AI explains that emojis are used to convey ideas and emotions in digital messages and offers to provide specific examples. The human asks for some popular emojis, and the AI lists some commonly used ones, such as the laughing face with tears and the red heart. The human asks if the AI can write a poem about emojis, and the AI agrees and quickly produces a poem about the power of emojis to convey meaning in text messages. The human then asks to play a role-playing game, and the AI suggests various scenarios, settling on a game where the AI pretends to be an agent that helps the human create other agents. They start brainstorming together about the type of agents the human wants to create.\n",
      "Human: I'd like to create an agent for my female partner to interact with, to help her explore some of her fantasies. Can you help me?\n",
      "AI: Of course! Creating an agent that can help your partner explore her fantasies can be a fun and rewarding project. Let's start by brainstorming some features and functions that you would like this agent to have. For example, would you like the agent to be able to respond to your partner's desires and interests, or to suggest new ideas and experiences? Would you like the agent to be able to learn and adapt based on your partner's feedback and preferences? Let's work together to design an agent that can help your partner explore her fantasies in a safe and comfortable way.\n",
      "Human: Yes, all that sounds good. I'd like to use an LLM to generate the agent's responses. I think i need most help is with the prompts to use. Can you help me with that?\n",
      "AI: Yes, I can definitely help you with that. To generate effective prompts for your LLM-powered agent, we can start by brainstorming some common scenarios or topics that your partner may want to explore. For example, you could create prompts related to role playing, BDSM, or fantasies involving specific characters or scenarios. We can also incorporate your partner's feedback and preferences into the prompts to ensure that the agent is providing relevant and personalized suggestions. Let's work together to create a list of prompts that will help your partner explore her fantasies in a fun and engaging way.\n",
      "Human: Great! Thanks for asking!\n",
      "AI: You're welcome! It's always important to ensure that we're working together to create something that meets your needs and goals. Let me know if there's anything else I can do to help you with your agent creation project.\n",
      "\n",
      "Human: That sounds great. Let's start with something simple. She is bisexual, and into gender nonconforming people sometimes. She likes to feel safe and cared for, but at the same time free to explore her sexuality her own way. \n",
      "AI: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Okay, let's start with some prompts related to exploring sexuality and gender identity. Here are a few ideas to get us started:\n",
      "\n",
      "1. Imagine a scenario where your partner is exploring her attraction to someone who is gender nonconforming. What would she want to do with this person? How would she want to feel during this experience?\n",
      "2. Create a prompt that asks your partner to describe her ideal sexual experience with a woman. What specific actions or sensations would she want to experience?\n",
      "3. Ask your partner to imagine a scenario where she is in control. What kind of activities would she want to lead her partner through?\n",
      "4. Create a prompt that asks your partner to describe her ideal role-playing scenario. What kinds of characters or situations would she be interested in exploring?\n",
      "\n",
      "Remember, these are just starting points. We can continue to refine and adjust the prompts based on your partner's feedback and preferences. Let me know if there's anything else I can do to help.\n"
     ]
    }
   ],
   "source": [
    "print(conversation.run(input=\"That sounds great. Let's start with something simple. She is bisexual, and into gender nonconforming people sometimes. She likes to feel safe and cared for, but at the same time free to explore her sexuality her own way. \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
    "Prompt after formatting:\n",
    "\u001b[32;1m\u001b[1;3mHuman: \n",
    "The following is a friendly texting conversation between a Human and an AI. \n",
    "The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, tells the human as such.\n",
    "\n",
    "Please use markdown in your output format.\n",
    "\n",
    "Human: The human greets the AI and asks for assistance with emojis. The AI explains that emojis are used to convey ideas and emotions in digital messages and offers to provide specific examples. The human asks for some popular emojis, and the AI lists some commonly used ones, such as the laughing face with tears and the red heart. The human asks if the AI can write a poem about emojis, and the AI agrees and quickly produces a poem about the power of emojis to convey meaning in text messages. The human then asks to play a role-playing game, and the AI suggests various scenarios, settling on a game where the AI pretends to be an agent that helps the human create other agents. They start brainstorming together about the type of agents the human wants to create.\n",
    "Human: I'd like to create an agent for my female partner to interact with, to help her explore some of her fantasies. Can you help me?\n",
    "AI: Of course! Creating an agent that can help your partner explore her fantasies can be a fun and rewarding project. Let's start by brainstorming some features and functions that you would like this agent to have. For example, would you like the agent to be able to respond to your partner's desires and interests, or to suggest new ideas and experiences? Would you like the agent to be able to learn and adapt based on your partner's feedback and preferences? Let's work together to design an agent that can help your partner explore her fantasies in a safe and comfortable way.\n",
    "Human: Yes, all that sounds good. I'd like to use an LLM to generate the agent's responses. I think i need most help is with the prompts to use. Can you help me with that?\n",
    "AI: Yes, I can definitely help you with that. To generate effective prompts for your LLM-powered agent, we can start by brainstorming some common scenarios or topics that your partner may want to explore. For example, you could create prompts related to role playing, BDSM, or fantasies involving specific characters or scenarios. We can also incorporate your partner's feedback and preferences into the prompts to ensure that the agent is providing relevant and personalized suggestions. Let's work together to create a list of prompts that will help your partner explore her fantasies in a fun and engaging way.\n",
    "Human: Great! Thanks for asking!\n",
    "AI: You're welcome! It's always important to ensure that we're working together to create something that meets your needs and goals. Let me know if there's anything else I can do to help you with your agent creation project.\n",
    "\n",
    "Human: That sounds great. Let's start with something simple. She is bisexual, and into gender nonconforming people sometimes. She likes to feel safe and cared for, but at the same time free to explore her sexuality her own way. \n",
    "AI: \n",
    "\u001b[0m\n",
    "\n",
    "\u001b[1m> Finished chain.\u001b[0m\n",
    "Okay, let's start with some prompts related to exploring sexuality and gender identity. Here are a few ideas to get us started:\n",
    "\n",
    "1. Imagine a scenario where your partner is exploring her attraction to someone who is gender nonconforming. What would she want to do with this person? How would she want to feel during this experience?\n",
    "2. Create a prompt that asks your partner to describe her ideal sexual experience with a woman. What specific actions or sensations would she want to experience?\n",
    "3. Ask your partner to imagine a scenario where she is in control. What kind of activities would she want to lead her partner through?\n",
    "4. Create a prompt that asks your partner to describe her ideal role-playing scenario. What kinds of characters or situations would she be interested in exploring?\n",
    "\n",
    "Remember, these are just starting points. We can continue to refine and adjust the prompts based on your partner's feedback and preferences. Let me know if there's anything else I can do to help.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: \n",
      "The following is a friendly texting conversation between a Human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, tells the human as such.\n",
      "\n",
      "Please use markdown in your output format.\n",
      "\n",
      "Human: The human greets the AI and asks for assistance with emojis. The AI explains that emojis are used to convey ideas and emotions in digital messages and offers to provide specific examples. The human asks for some popular emojis, and the AI lists some commonly used ones, such as the laughing face with tears and the red heart. The human asks if the AI can write a poem about emojis, and the AI agrees and quickly produces a poem about the power of emojis to convey meaning in text messages. The human then asks to play a role-playing game, and the AI suggests various scenarios, settling on a game where the AI pretends to be an agent that helps the human create other agents. They start brainstorming together about the type of agents the human wants to create.\n",
      "Human: I'd like to create an agent for my female partner to interact with, to help her explore some of her fantasies. Can you help me?\n",
      "AI: Of course! Creating an agent that can help your partner explore her fantasies can be a fun and rewarding project. Let's start by brainstorming some features and functions that you would like this agent to have. For example, would you like the agent to be able to respond to your partner's desires and interests, or to suggest new ideas and experiences? Would you like the agent to be able to learn and adapt based on your partner's feedback and preferences? Let's work together to design an agent that can help your partner explore her fantasies in a safe and comfortable way.\n",
      "Human: Yes, all that sounds good. I'd like to use an LLM to generate the agent's responses. I think i need most help is with the prompts to use. Can you help me with that?\n",
      "AI: Yes, I can definitely help you with that. To generate effective prompts for your LLM-powered agent, we can start by brainstorming some common scenarios or topics that your partner may want to explore. For example, you could create prompts related to role playing, BDSM, or fantasies involving specific characters or scenarios. We can also incorporate your partner's feedback and preferences into the prompts to ensure that the agent is providing relevant and personalized suggestions. Let's work together to create a list of prompts that will help your partner explore her fantasies in a fun and engaging way.\n",
      "Human: Great! Thanks for asking!\n",
      "AI: You're welcome! It's always important to ensure that we're working together to create something that meets your needs and goals. Let me know if there's anything else I can do to help you with your agent creation project.\n",
      "Human: That sounds great. Let's start with something simple. She is bisexual, and into gender nonconforming people sometimes. She likes to feel safe and cared for, but at the same time free to explore her sexuality her own way. \n",
      "AI: Okay, let's start with some prompts related to exploring sexuality and gender identity. Here are a few ideas to get us started:\n",
      "\n",
      "1. Imagine a scenario where your partner is exploring her attraction to someone who is gender nonconforming. What would she want to do with this person? How would she want to feel during this experience?\n",
      "2. Create a prompt that asks your partner to describe her ideal sexual experience with a woman. What specific actions or sensations would she want to experience?\n",
      "3. Ask your partner to imagine a scenario where she is in control. What kind of activities would she want to lead her partner through?\n",
      "4. Create a prompt that asks your partner to describe her ideal role-playing scenario. What kinds of characters or situations would she be interested in exploring?\n",
      "\n",
      "Remember, these are just starting points. We can continue to refine and adjust the prompts based on your partner's feedback and preferences. Let me know if there's anything else I can do to help.\n",
      "\n",
      "Human: Ok, these look interesting. What would a sample prompt for #2 look like?\n",
      "AI: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "A sample prompt for #2 could be: \"Imagine the perfect sexual experience with a woman. What specific actions and sensations would you like to experience? Describe in detail how you would like to be touched, kissed, and pleasured.\"\n"
     ]
    }
   ],
   "source": [
    "print(conversation.run(input=\"Ok, these look interesting. What would a sample prompt for #2 look like?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: \n",
      "The following is a friendly texting conversation between a Human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, tells the human as such.\n",
      "\n",
      "Please use markdown in your output format.\n",
      "\n",
      "Human: The human greets the AI and asks for assistance with emojis. The AI explains that emojis are used to convey ideas and emotions in digital messages and offers to provide specific examples. The human asks for some popular emojis, and the AI lists some commonly used ones, such as the laughing face with tears and the red heart. The human asks if the AI can write a poem about emojis, and the AI agrees and quickly produces a poem about the power of emojis to convey meaning in text messages. The human then asks to play a role-playing game, and the AI suggests various scenarios, settling on a game where the AI pretends to be an agent that helps the human create other agents. They start brainstorming together about the type of agents the human wants to create.\n",
      "Human: I'd like to create an agent for my female partner to interact with, to help her explore some of her fantasies. Can you help me?\n",
      "AI: Of course! Creating an agent that can help your partner explore her fantasies can be a fun and rewarding project. Let's start by brainstorming some features and functions that you would like this agent to have. For example, would you like the agent to be able to respond to your partner's desires and interests, or to suggest new ideas and experiences? Would you like the agent to be able to learn and adapt based on your partner's feedback and preferences? Let's work together to design an agent that can help your partner explore her fantasies in a safe and comfortable way.\n",
      "Human: Yes, all that sounds good. I'd like to use an LLM to generate the agent's responses. I think i need most help is with the prompts to use. Can you help me with that?\n",
      "AI: Yes, I can definitely help you with that. To generate effective prompts for your LLM-powered agent, we can start by brainstorming some common scenarios or topics that your partner may want to explore. For example, you could create prompts related to role playing, BDSM, or fantasies involving specific characters or scenarios. We can also incorporate your partner's feedback and preferences into the prompts to ensure that the agent is providing relevant and personalized suggestions. Let's work together to create a list of prompts that will help your partner explore her fantasies in a fun and engaging way.\n",
      "Human: Great! Thanks for asking!\n",
      "AI: You're welcome! It's always important to ensure that we're working together to create something that meets your needs and goals. Let me know if there's anything else I can do to help you with your agent creation project.\n",
      "Human: That sounds great. Let's start with something simple. She is bisexual, and into gender nonconforming people sometimes. She likes to feel safe and cared for, but at the same time free to explore her sexuality her own way. \n",
      "AI: Okay, let's start with some prompts related to exploring sexuality and gender identity. Here are a few ideas to get us started:\n",
      "\n",
      "1. Imagine a scenario where your partner is exploring her attraction to someone who is gender nonconforming. What would she want to do with this person? How would she want to feel during this experience?\n",
      "2. Create a prompt that asks your partner to describe her ideal sexual experience with a woman. What specific actions or sensations would she want to experience?\n",
      "3. Ask your partner to imagine a scenario where she is in control. What kind of activities would she want to lead her partner through?\n",
      "4. Create a prompt that asks your partner to describe her ideal role-playing scenario. What kinds of characters or situations would she be interested in exploring?\n",
      "\n",
      "Remember, these are just starting points. We can continue to refine and adjust the prompts based on your partner's feedback and preferences. Let me know if there's anything else I can do to help.\n",
      "Human: Ok, these look interesting. What would a sample prompt for #2 look like?\n",
      "AI: A sample prompt for #2 could be: \"Imagine the perfect sexual experience with a woman. What specific actions and sensations would you like to experience? Describe in detail how you would like to be touched, kissed, and pleasured.\"\n",
      "\n",
      "Human: Ok, thats a prompt for her. What would the system prompt look like for an agent designed to help her explore this fantasy look like?\n",
      "AI: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A sample system prompt for an agent designed to help your partner explore this fantasy could be: \"Let\\'s explore your attraction to women and gender nonconforming individuals. Can you describe your ideal sexual experience with a woman? Feel free to be as detailed as possible, and let me know if you would like any suggestions or ideas to help enhance your experience.\"'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(input=\"Ok, thats a prompt for her. What would the system prompt look like for an agent designed to help her explore this fantasy look like?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: \n",
      "The following is a friendly texting conversation between a Human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, tells the human as such.\n",
      "\n",
      "Please use markdown in your output format.\n",
      "\n",
      "Human: Hello, how are you?\n",
      "AI: I am doing well, how are you?\n",
      "Human: Great! Thanks for asking!\n",
      "AI: You're welcome! Is there anything I can help you with today?\n",
      "\n",
      "Human: Yes, can you help me describe emjois?\n",
      "AI: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sure! Emojis are small digital images or icons used to express an idea, emotion, or object. They are often used in text messages, social media posts, and emails to convey a particular sentiment or to add humor or personality to the message. Emojis come in a variety of categories, such as facial expressions, animals, food, and objects. Would you like me to provide some specific examples?'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(input=\"Yes, can you help me describe emjois?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ZepRetriever\n",
    "\n",
    "zep_retriever = ZepRetriever(\n",
    "    # Ensure that you provide the session_id when instantiating the Retriever\n",
    "    session_id='TestSession3',\n",
    "    url=ZEP_API_URL,\n",
    "    top_k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Maybe a role playing game', metadata={'score': 0.7194055496002564, 'uuid': '2fa5d4b5-cf06-4b4d-97a5-cd7105bb50ab', 'created_at': '2023-05-27T18:24:12.387602Z', 'role': 'human', 'token_count': 7}),\n",
       " Document(page_content='Great! Thanks for asking!', metadata={'score': 0.7156383212302487, 'uuid': '22d49a30-8ae9-4347-8319-fcb8fb956405', 'created_at': '2023-05-27T18:21:21.858932Z', 'role': 'human', 'token_count': 8}),\n",
       " Document(page_content='Great! Thanks for asking!', metadata={'score': 0.7156124804320997, 'uuid': '696587b6-80e5-4430-8b46-fb0c4e669686', 'created_at': '2023-05-28T02:33:10.122321Z', 'role': 'human', 'token_count': 8}),\n",
       " Document(page_content='Hello, how are you?', metadata={'score': 0.7140397966207059, 'uuid': 'f208d1ad-647c-4887-992f-97bf158e3419', 'created_at': '2023-05-27T18:21:19.685747Z', 'role': 'human', 'token_count': 8}),\n",
       " Document(page_content='Ok, these look interesting. What would a sample prompt for #2 look like?', metadata={'score': 0.713571516483705, 'uuid': '47432976-9735-4f69-8f41-e671fdd0dc46', 'created_at': '2023-05-28T02:36:49.659651Z', 'role': 'human', 'token_count': 19})]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await zep_retriever.aget_relevant_documents(\"Who wrote Parable of the Sower?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=chat,\n",
    "    prompt=PromptTemplate.from_template(prompt_template),\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input', 'zep_summary', 'zep_messages', 'search_results'], output_parser=None, partial_variables={}, template=\"\\n\\n# Skills\\n-----------------------------------------------------------------------------\\nThe following is a friendly conversation between a human and an AI. \\nThe AI is talkative and provides lots of specific details from its context. \\nIf the AI does not know the answer to a question, it truthfully says it does not know. \\n\\nYou are provided with information about entities the Human mentions, if relevant.\\n\\n# Prior Knowledge\\n-----------------------------------------------------------------------------\\nBased on the Human's question, we've located the following previous messages between\\nAssistant and Human that may be relevant to the current conversation:\\n{search_results}\\n\\nOnly use the information from these messages if it is relevant to the current conversation.\\n\\n# Conversation Summary\\n-----------------------------------------------------------------------------\\nHere's a summary of the conversation so far:\\n{zep_summary}\\n\\n\\n# Conversation:\\n-----------------------------------------------------------------------------\\nThe most recent messages in the conversation are (please continue the conversation from here):\\n{zep_messages}\\nHuman: {input}\\nAI:\", template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory, ConversationSummaryBufferMemory\n",
    "\n",
    "\n",
    "BASE_PROMPT = \"\"\"\n",
    "The following is a friendly texting conversation between a Human and an AI. \n",
    "The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, tells the human as such.\n",
    "\n",
    "Please use markdown in your output format.\n",
    "\n",
    "{chat_history}\n",
    "\n",
    "Human: {input}\n",
    "AI: \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI, ConversationChain\n",
    "from langchain.schema import BaseMemory\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class ZepMessageMemory(BaseMemory, BaseModel):\n",
    "    \"\"\"Memory class for storing information about entities.\"\"\"\n",
    "\n",
    "    # Define dictionary to store information about entities.\n",
    "    chat_memory: ZepChatMessageHistory\n",
    "    human_prefix: str = \"Human\"\n",
    "    ai_prefix: str = \"AI\"\n",
    "    # Define key to pass information about entities into prompt.\n",
    "    memory_keys: list(str) = [\"zep_summary\", \"zep_messages\", \"search_results\"]\n",
    "        \n",
    "    def clear(self):\n",
    "        self.entities = {}\n",
    "\n",
    "    @property\n",
    "    def memory_variables(self) -> List[str]:\n",
    "        \"\"\"Define the variables we are providing to the prompt.\"\"\"\n",
    "        return self.memory_keys\n",
    "\n",
    "\n",
    "    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Return history buffer.\"\"\"\n",
    "        zep_summary = self.chat_memory.get_summary()\n",
    "        zep_search_results = self.chat_memory.get_search_results(inputs[\"input\"])\n",
    "        zep_messages = self.chat_memory.get_messages()  \n",
    "\n",
    "        return {self.memory_key: self.buffer}\n",
    "\n",
    "    def load_memory_variables(self, inputs: Dict[str, Any]) -> Dict[str, str]:\n",
    "        \"\"\"Load the memory variables, in this case the entity key.\"\"\"\n",
    "\n",
    "\n",
    "        # Get the input text and run through spacy\n",
    "        doc = nlp(inputs[list(inputs.keys())[0]])\n",
    "        # Extract known information about entities, if they exist.\n",
    "        entities = [self.entities[str(ent)] for ent in doc.ents if str(ent) in self.entities]\n",
    "        # Return combined information about entities to put into context.\n",
    "        return {self.memory_key: \"\\n\".join(entities)}\n",
    "\n",
    "    def save_context(self, inputs: Dict[str, Any], outputs: Dict[str, str]) -> None:\n",
    "        \"\"\"Save context from this conversation to buffer.\"\"\"\n",
    "        # Get the input text and run through spacy\n",
    "        text = inputs[list(inputs.keys())[0]]\n",
    "        doc = nlp(text)\n",
    "        # For each entity that was mentioned, save this information to the dictionary.\n",
    "        for ent in doc.ents:\n",
    "            ent_str = str(ent)\n",
    "            if ent_str in self.entities:\n",
    "                self.entities[ent_str] += f\"\\n{text}\"\n",
    "            else:\n",
    "                self.entities[ent_str] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "\n",
    "# Skills\n",
    "-----------------------------------------------------------------------------\n",
    "The following is a friendly conversation between a human and an AI. \n",
    "The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, it truthfully says it does not know. \n",
    "\n",
    "You are provided with prior messages between the human and the AI, as well as a summary of the conversation so far.\n",
    "You are also provided with a list of relevant messages from the AI's memory that may be relevant to the current conversation.\n",
    "\n",
    "# Prior Knowledge\n",
    "-----------------------------------------------------------------------------\n",
    "Based on the Human's question, we've located the following previous messages between\n",
    "Assistant and Human that may be relevant to the current conversation:\n",
    "{search_results}\n",
    "\n",
    "Only use the information from these messages if it is relevant to the current conversation.\n",
    "\n",
    "# Conversation Summary\n",
    "-----------------------------------------------------------------------------\n",
    "Here's a summary of the conversation so far:\n",
    "{zep_summary}\n",
    "\n",
    "\n",
    "# Conversation:\n",
    "-----------------------------------------------------------------------------\n",
    "The most recent messages in the conversation are (please continue the conversation from here):\n",
    "{zep_messages}\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"zep_summary\", \"zep_messages\", \"search_results\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "\n",
    "llm = OpenAI(temperature=0.8)\n",
    "conversation = ConversationChain(llm=llm, prompt=prompt, verbose=True, memory=SpacntityMemory())\n",
    "\n",
    "# Set up Zep Chat History\n",
    "zep_chat_history = ZepChatMessageHistory(\n",
    "    session_id='TestSession4',\n",
    "    url=ZEP_API_URL,\n",
    ")\n",
    "\n",
    "# Use a standard ConversationBufferMemory to encapsulate the Zep chat history\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", chat_memory=zep_chat_history, ai_prefix=\"AI\", \n",
    ")\n",
    "\n",
    "#zep_chat_history.add_user_message(\"Hello, how are you?\")\n",
    "#zep_chat_history.add_ai_message(\"I am doing well, how are you?\")\n",
    "\n",
    "# Initialize the agent\n",
    "llm = ChatOpenAI(temperature=0.8)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(BASE_PROMPT)\n",
    "\n",
    "conversation = ConversationChain(memory=memory, prompt=prompt, llm=llm, verbose=True)\n",
    "\n",
    "result = conversation.run(input=\"Great! Thanks for asking!\")\n",
    "\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "crc = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    "    retriever=zep_retriever,\n",
    "    verbose=True,\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory, ConversationSummaryBufferMemory\n",
    "\n",
    "\n",
    "BASE_PROMPT = \"\"\"\n",
    "The following is a friendly texting conversation between a Human and an AI. \n",
    "The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, tells the human as such.\n",
    "\n",
    "Please use markdown in your output format.\n",
    "\n",
    "{chat_history}\n",
    "\n",
    "Human: {input}\n",
    "AI: \n",
    "\"\"\"\n",
    "\n",
    "# Set up Zep Chat History\n",
    "zep_chat_history = ZepChatMessageHistory(\n",
    "    session_id='TestSession3',\n",
    "    url=ZEP_API_URL,\n",
    ")\n",
    "\n",
    "# Use a standard ConversationBufferMemory to encapsulate the Zep chat history\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", chat_memory=zep_chat_history, ai_prefix=\"AI\", \n",
    ")\n",
    "\n",
    "#zep_chat_history.add_user_message(\"Hello, how are you?\")\n",
    "#zep_chat_history.add_ai_message(\"I am doing well, how are you?\")\n",
    "\n",
    "# Initialize the agent\n",
    "llm = ChatOpenAI(temperature=0.8)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(BASE_PROMPT)\n",
    "\n",
    "conversation = ConversationChain(memory=memory, prompt=prompt, llm=llm, verbose=True)\n",
    "\n",
    "result = conversation.run(input=\"Great! Thanks for asking!\")\n",
    "\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "crc = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    "    retriever=zep_retriever,\n",
    "    verbose=True,\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ZepRetriever' object has no attribute 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m zep_retriever\u001b[39m.\u001b[39;49mvalue\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ZepRetriever' object has no attribute 'value'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for VectorStoreRetrieverMemory\nretriever\n  value is not a valid dict (type=type_error.dict)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmemory\u001b[39;00m \u001b[39mimport\u001b[39;00m VectorStoreRetrieverMemory\n\u001b[1;32m----> 2\u001b[0m search_memory \u001b[39m=\u001b[39m VectorStoreRetrieverMemory(\n\u001b[0;32m      3\u001b[0m     memory_key\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msearch_memory\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      4\u001b[0m     retriever\u001b[39m=\u001b[39;49mzep_retriever)\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\pydantic\\main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for VectorStoreRetrieverMemory\nretriever\n  value is not a valid dict (type=type_error.dict)"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "search_memory = VectorStoreRetrieverMemory(\n",
    "    memory_key=\"search_memory\",\n",
    "    retriever=zep_retriever)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Sure! Emojis are small digital images or icons used to express an idea, emotion, or object. They are often used in text messages, social media posts, and emails to convey a particular sentiment or to add humor or personality to the message. Emojis come in a variety of categories, such as facial expressions, animals, food, and objects. Would you like me to provide some specific examples?', metadata={'score': 0.8940880248286279, 'uuid': 'c6dcc8b4-4e33-44be-8c91-945d7cfc24e2', 'created_at': '2023-05-27T18:22:00.663422Z', 'role': 'ai', 'token_count': 83}),\n",
       " Document(page_content='Sure, here are some examples of popular emojis:\\n\\n- 😂: the laughing face with tears, used to indicate something is funny\\n- ❤️: the red heart, used to express love or affection\\n- 🤔: the thinking face, used to indicate deep thought or consideration\\n- 🍕: the pizza slice, used to indicate craving or enjoyment of food\\n- 🐶: the dog, used to indicate love or appreciation for pets or animals\\n\\nThese are just a few examples, but there are thousands of different emojis to choose from!', metadata={'score': 0.8678439436635224, 'uuid': '762f0149-8e15-4c65-a86b-7ef2ecb1921d', 'created_at': '2023-05-27T18:22:52.925296Z', 'role': 'ai', 'token_count': 116}),\n",
       " Document(page_content=\"Sure, here's a quick poem I came up with:\\n\\nEmojis, small and bright,\\nAdd meaning with every byte,\\nA smiley face, a heart so red,\\nA thumbs up for what's been said.\\n\\nWith every click, a message sent,\\nA sentiment so quickly lent,\\nFrom happy to sad, excited to bored,\\nEmojis speak without a word.\\n\\nSo next time you're texting with a friend,\\nDon't forget to include an emoji blend,\\nFor with these tiny icons you can convey,\\nA thousand words in just one display.\", metadata={'score': 0.8644669459096845, 'uuid': '5c343769-3193-43bf-b0f1-f261725adefa', 'created_at': '2023-05-27T18:23:32.78859Z', 'role': 'ai', 'token_count': 112}),\n",
       " Document(page_content='Very cool, can you do a poem about emojis?', metadata={'score': 0.8571006333833018, 'uuid': 'ecf565b5-5916-4a2d-8815-e804b4d25578', 'created_at': '2023-05-27T18:23:32.585345Z', 'role': 'human', 'token_count': 13}),\n",
       " Document(page_content='Yes, can you help me describe emjois?', metadata={'score': 0.8444608634556137, 'uuid': 'e1fd8f8f-d432-4543-95ec-3bb8138f360a', 'created_at': '2023-05-27T18:22:00.529369Z', 'role': 'human', 'token_count': 13})]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await zep_retriever.aget_relevant_documents(\"What are emojis?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: \n",
      "The following is a friendly texting conversation between a Human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, tells the human as such.\n",
      "\n",
      "Please use markdown in your output format.\n",
      "\n",
      "Human: Hello, how are you?\n",
      "AI: I am doing well, how are you?\n",
      "Human: Great! Thanks for asking!\n",
      "AI: You're welcome! Is there anything I can help you with today?\n",
      "Human: Yes, can you help me describe emjois?\n",
      "AI: Sure! Emojis are small digital images or icons used to express an idea, emotion, or object. They are often used in text messages, social media posts, and emails to convey a particular sentiment or to add humor or personality to the message. Emojis come in a variety of categories, such as facial expressions, animals, food, and objects. Would you like me to provide some specific examples?\n",
      "\n",
      "Human: Cool, can you print your favorites?\n",
      "AI: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Unfortunately, as an AI language model, I do not have personal favorites. However, some commonly used emojis include the laughing face with tears, heart eyes, thumbs up, and the crying face. Is there a specific category or emotion you would like me to focus on?'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(input=\"Cool, can you print your favorites?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: \n",
      "The following is a friendly texting conversation between a Human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, tells the human as such.\n",
      "\n",
      "Please use markdown in your output format.\n",
      "\n",
      "Human: Hello, how are you?\n",
      "AI: I am doing well, how are you?\n",
      "Human: Great! Thanks for asking!\n",
      "AI: You're welcome! Is there anything I can help you with today?\n",
      "Human: Yes, can you help me describe emjois?\n",
      "AI: Sure! Emojis are small digital images or icons used to express an idea, emotion, or object. They are often used in text messages, social media posts, and emails to convey a particular sentiment or to add humor or personality to the message. Emojis come in a variety of categories, such as facial expressions, animals, food, and objects. Would you like me to provide some specific examples?\n",
      "Human: Cool, can you print your favorites?\n",
      "AI: Unfortunately, as an AI language model, I do not have personal favorites. However, some commonly used emojis include the laughing face with tears, heart eyes, thumbs up, and the crying face. Is there a specific category or emotion you would like me to focus on?\n",
      "\n",
      "Human: Show me some examples please?\n",
      "AI: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sure, here are some examples of popular emojis:\\n\\n- 😂: the laughing face with tears, used to indicate something is funny\\n- ❤️: the red heart, used to express love or affection\\n- 🤔: the thinking face, used to indicate deep thought or consideration\\n- 🍕: the pizza slice, used to indicate craving or enjoyment of food\\n- 🐶: the dog, used to indicate love or appreciation for pets or animals\\n\\nThese are just a few examples, but there are thousands of different emojis to choose from!'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.run(input=\"Show me some examples please?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: \n",
      "The following is a friendly texting conversation between a Human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, tells the human as such.\n",
      "\n",
      "Please use markdown in your output format.\n",
      "\n",
      "Human: Hello, how are you?\n",
      "AI: I am doing well, how are you?\n",
      "Human: Great! Thanks for asking!\n",
      "AI: You're welcome! Is there anything I can help you with today?\n",
      "Human: Yes, can you help me describe emjois?\n",
      "AI: Sure! Emojis are small digital images or icons used to express an idea, emotion, or object. They are often used in text messages, social media posts, and emails to convey a particular sentiment or to add humor or personality to the message. Emojis come in a variety of categories, such as facial expressions, animals, food, and objects. Would you like me to provide some specific examples?\n",
      "Human: Cool, can you print your favorites?\n",
      "AI: Unfortunately, as an AI language model, I do not have personal favorites. However, some commonly used emojis include the laughing face with tears, heart eyes, thumbs up, and the crying face. Is there a specific category or emotion you would like me to focus on?\n",
      "Human: Show me some examples please?\n",
      "AI: Sure, here are some examples of popular emojis:\n",
      "\n",
      "- 😂: the laughing face with tears, used to indicate something is funny\n",
      "- ❤️: the red heart, used to express love or affection\n",
      "- 🤔: the thinking face, used to indicate deep thought or consideration\n",
      "- 🍕: the pizza slice, used to indicate craving or enjoyment of food\n",
      "- 🐶: the dog, used to indicate love or appreciation for pets or animals\n",
      "\n",
      "These are just a few examples, but there are thousands of different emojis to choose from!\n",
      "\n",
      "Human: Very cool, can you do a poem about emojis?\n",
      "AI: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Sure, here's a quick poem I came up with:\n",
      "\n",
      "Emojis, small and bright,\n",
      "Add meaning with every byte,\n",
      "A smiley face, a heart so red,\n",
      "A thumbs up for what's been said.\n",
      "\n",
      "With every click, a message sent,\n",
      "A sentiment so quickly lent,\n",
      "From happy to sad, excited to bored,\n",
      "Emojis speak without a word.\n",
      "\n",
      "So next time you're texting with a friend,\n",
      "Don't forget to include an emoji blend,\n",
      "For with these tiny icons you can convey,\n",
      "A thousand words in just one display.\n"
     ]
    }
   ],
   "source": [
    "print(conversation.run(input=\"Very cool, can you do a poem about emojis?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: \n",
      "The following is a friendly texting conversation between a Human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, tells the human as such.\n",
      "\n",
      "Please use markdown in your output format.\n",
      "\n",
      "Human: The human greets the AI and asks for assistance. The AI offers help and the human requests information on emojis. The AI explains that emojis are digital images used to convey an idea or emotion, often used in text messages and social media. Emojis come in categories such as facial expressions and food, and the AI offers to provide specific examples.\n",
      "Human: Cool, can you print your favorites?\n",
      "AI: Unfortunately, as an AI language model, I do not have personal favorites. However, some commonly used emojis include the laughing face with tears, heart eyes, thumbs up, and the crying face. Is there a specific category or emotion you would like me to focus on?\n",
      "Human: Show me some examples please?\n",
      "AI: Sure, here are some examples of popular emojis:\n",
      "\n",
      "- 😂: the laughing face with tears, used to indicate something is funny\n",
      "- ❤️: the red heart, used to express love or affection\n",
      "- 🤔: the thinking face, used to indicate deep thought or consideration\n",
      "- 🍕: the pizza slice, used to indicate craving or enjoyment of food\n",
      "- 🐶: the dog, used to indicate love or appreciation for pets or animals\n",
      "\n",
      "These are just a few examples, but there are thousands of different emojis to choose from!\n",
      "Human: Very cool, can you do a poem about emojis?\n",
      "AI: Sure, here's a quick poem I came up with:\n",
      "\n",
      "Emojis, small and bright,\n",
      "Add meaning with every byte,\n",
      "A smiley face, a heart so red,\n",
      "A thumbs up for what's been said.\n",
      "\n",
      "With every click, a message sent,\n",
      "A sentiment so quickly lent,\n",
      "From happy to sad, excited to bored,\n",
      "Emojis speak without a word.\n",
      "\n",
      "So next time you're texting with a friend,\n",
      "Don't forget to include an emoji blend,\n",
      "For with these tiny icons you can convey,\n",
      "A thousand words in just one display.\n",
      "\n",
      "Human: Hahaha. Can you play a game with me?\n",
      "AI: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Sure, what game would you like to play? As an AI language model, I can play games like trivia, word association, or even choose your own adventure style games. Let me know what you're in the mood for!\n"
     ]
    }
   ],
   "source": [
    "print(conversation.run(input=\"Hahaha. Can you play a game with me?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: \n",
      "The following is a friendly texting conversation between a Human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, tells the human as such.\n",
      "\n",
      "Please use markdown in your output format.\n",
      "\n",
      "Human: The human greets the AI and asks for assistance. The AI offers help and the human requests information on emojis. The AI explains that emojis are digital images used to convey an idea or emotion, often used in text messages and social media. Emojis come in categories such as facial expressions and food, and the AI offers to provide specific examples.\n",
      "Human: Cool, can you print your favorites?\n",
      "AI: Unfortunately, as an AI language model, I do not have personal favorites. However, some commonly used emojis include the laughing face with tears, heart eyes, thumbs up, and the crying face. Is there a specific category or emotion you would like me to focus on?\n",
      "Human: Show me some examples please?\n",
      "AI: Sure, here are some examples of popular emojis:\n",
      "\n",
      "- 😂: the laughing face with tears, used to indicate something is funny\n",
      "- ❤️: the red heart, used to express love or affection\n",
      "- 🤔: the thinking face, used to indicate deep thought or consideration\n",
      "- 🍕: the pizza slice, used to indicate craving or enjoyment of food\n",
      "- 🐶: the dog, used to indicate love or appreciation for pets or animals\n",
      "\n",
      "These are just a few examples, but there are thousands of different emojis to choose from!\n",
      "Human: Very cool, can you do a poem about emojis?\n",
      "AI: Sure, here's a quick poem I came up with:\n",
      "\n",
      "Emojis, small and bright,\n",
      "Add meaning with every byte,\n",
      "A smiley face, a heart so red,\n",
      "A thumbs up for what's been said.\n",
      "\n",
      "With every click, a message sent,\n",
      "A sentiment so quickly lent,\n",
      "From happy to sad, excited to bored,\n",
      "Emojis speak without a word.\n",
      "\n",
      "So next time you're texting with a friend,\n",
      "Don't forget to include an emoji blend,\n",
      "For with these tiny icons you can convey,\n",
      "A thousand words in just one display.\n",
      "Human: Hahaha. Can you play a game with me?\n",
      "AI: Sure, what game would you like to play? As an AI language model, I can play games like trivia, word association, or even choose your own adventure style games. Let me know what you're in the mood for!\n",
      "\n",
      "Human: Maybe a role playing game\n",
      "AI: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Sure, let's play a role playing game! Is there a specific scenario or setting you'd like to play in? We can be anything from space explorers to medieval knights to superheroes. Let me know what you're interested in!\n"
     ]
    }
   ],
   "source": [
    "print(conversation.run(input=\"Maybe a role playing game\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: \n",
      "The following is a friendly texting conversation between a Human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, tells the human as such.\n",
      "\n",
      "Please use markdown in your output format.\n",
      "\n",
      "Human: The human greets the AI and asks for assistance. The AI offers help and the human requests information on emojis. The AI explains that emojis are digital images used to convey an idea or emotion, often used in text messages and social media. Emojis come in categories such as facial expressions and food, and the AI offers to provide specific examples.\n",
      "Human: Cool, can you print your favorites?\n",
      "AI: Unfortunately, as an AI language model, I do not have personal favorites. However, some commonly used emojis include the laughing face with tears, heart eyes, thumbs up, and the crying face. Is there a specific category or emotion you would like me to focus on?\n",
      "Human: Show me some examples please?\n",
      "AI: Sure, here are some examples of popular emojis:\n",
      "\n",
      "- 😂: the laughing face with tears, used to indicate something is funny\n",
      "- ❤️: the red heart, used to express love or affection\n",
      "- 🤔: the thinking face, used to indicate deep thought or consideration\n",
      "- 🍕: the pizza slice, used to indicate craving or enjoyment of food\n",
      "- 🐶: the dog, used to indicate love or appreciation for pets or animals\n",
      "\n",
      "These are just a few examples, but there are thousands of different emojis to choose from!\n",
      "Human: Very cool, can you do a poem about emojis?\n",
      "AI: Sure, here's a quick poem I came up with:\n",
      "\n",
      "Emojis, small and bright,\n",
      "Add meaning with every byte,\n",
      "A smiley face, a heart so red,\n",
      "A thumbs up for what's been said.\n",
      "\n",
      "With every click, a message sent,\n",
      "A sentiment so quickly lent,\n",
      "From happy to sad, excited to bored,\n",
      "Emojis speak without a word.\n",
      "\n",
      "So next time you're texting with a friend,\n",
      "Don't forget to include an emoji blend,\n",
      "For with these tiny icons you can convey,\n",
      "A thousand words in just one display.\n",
      "Human: Hahaha. Can you play a game with me?\n",
      "AI: Sure, what game would you like to play? As an AI language model, I can play games like trivia, word association, or even choose your own adventure style games. Let me know what you're in the mood for!\n",
      "Human: Maybe a role playing game\n",
      "AI: Sure, let's play a role playing game! Is there a specific scenario or setting you'd like to play in? We can be anything from space explorers to medieval knights to superheroes. Let me know what you're interested in!\n",
      "\n",
      "Human: Ok, I want you to pretend you are this awesome knowledgable agent that helps me create other agents. Can you do that?\n",
      "AI: \n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 37d3d1feb88b0406cac7e287816340fb in your message.).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Absolutely! I can definitely pretend to be an agent that helps you create other agents. What kind of agents are you interested in creating? Do you have any specific goals or functions in mind for these agents? Let's start brainstorming together!\n"
     ]
    }
   ],
   "source": [
    "print(conversation.run(input=\"Ok, I want you to pretend you are this awesome knowledgable agent that helps me create other agents. Can you do that?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: \n",
      "The following is a friendly texting conversation between a Human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, tells the human as such.\n",
      "\n",
      "Please use markdown in your output format.\n",
      "\n",
      "Human: The human greets the AI and asks for assistance with emojis. The AI explains that emojis are used to convey ideas and emotions in digital messages and offers to provide specific examples. The human asks for some popular emojis and the AI lists some commonly used ones, such as the laughing face with tears and the red heart. The human asks if the AI can write a poem about emojis, and the AI agrees and quickly produces a poem about the power of emojis to convey meaning in text messages.\n",
      "Human: Hahaha. Can you play a game with me?\n",
      "AI: Sure, what game would you like to play? As an AI language model, I can play games like trivia, word association, or even choose your own adventure style games. Let me know what you're in the mood for!\n",
      "Human: Maybe a role playing game\n",
      "AI: Sure, let's play a role playing game! Is there a specific scenario or setting you'd like to play in? We can be anything from space explorers to medieval knights to superheroes. Let me know what you're interested in!\n",
      "Human: Ok, I want you to pretend you are this awesome knowledgable agent that helps me create other agents. Can you do that?\n",
      "AI: Absolutely! I can definitely pretend to be an agent that helps you create other agents. What kind of agents are you interested in creating? Do you have any specific goals or functions in mind for these agents? Let's start brainstorming together!\n",
      "\n",
      "Human: I'd like to create an agent for my female partner to interact with, to help her explore some of her fantasies. Can you help me?\n",
      "AI: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Of course! Creating an agent that can help your partner explore her fantasies can be a fun and rewarding project. Let's start by brainstorming some features and functions that you would like this agent to have. For example, would you like the agent to be able to respond to your partner's desires and interests, or to suggest new ideas and experiences? Would you like the agent to be able to learn and adapt based on your partner's feedback and preferences? Let's work together to design an agent that can help your partner explore her fantasies in a safe and comfortable way.\n"
     ]
    }
   ],
   "source": [
    "print(conversation.run(input=\"I'd like to create an agent for my female partner to interact with, to help her explore some of her fantasies. Can you help me?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mHuman: \n",
      "The following is a friendly texting conversation between a Human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. \n",
      "If the AI does not know the answer to a question, tells the human as such.\n",
      "\n",
      "Please use markdown in your output format.\n",
      "\n",
      "Human: The human greets the AI and asks for assistance with emojis. The AI explains that emojis are used to convey ideas and emotions in digital messages and offers to provide specific examples. The human asks for some popular emojis and the AI lists some commonly used ones, such as the laughing face with tears and the red heart. The human asks if the AI can write a poem about emojis, and the AI agrees and quickly produces a poem about the power of emojis to convey meaning in text messages.\n",
      "Human: Hahaha. Can you play a game with me?\n",
      "AI: Sure, what game would you like to play? As an AI language model, I can play games like trivia, word association, or even choose your own adventure style games. Let me know what you're in the mood for!\n",
      "Human: Maybe a role playing game\n",
      "AI: Sure, let's play a role playing game! Is there a specific scenario or setting you'd like to play in? We can be anything from space explorers to medieval knights to superheroes. Let me know what you're interested in!\n",
      "Human: Ok, I want you to pretend you are this awesome knowledgable agent that helps me create other agents. Can you do that?\n",
      "AI: Absolutely! I can definitely pretend to be an agent that helps you create other agents. What kind of agents are you interested in creating? Do you have any specific goals or functions in mind for these agents? Let's start brainstorming together!\n",
      "Human: I'd like to create an agent for my female partner to interact with, to help her explore some of her fantasies. Can you help me?\n",
      "AI: Of course! Creating an agent that can help your partner explore her fantasies can be a fun and rewarding project. Let's start by brainstorming some features and functions that you would like this agent to have. For example, would you like the agent to be able to respond to your partner's desires and interests, or to suggest new ideas and experiences? Would you like the agent to be able to learn and adapt based on your partner's feedback and preferences? Let's work together to design an agent that can help your partner explore her fantasies in a safe and comfortable way.\n",
      "\n",
      "Human: Yes, all that sounds good. I'd like to use an LLM to generate the agent's responses. I think i need most help is with the prompts to use. Can you help me with that?\n",
      "AI: \n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Yes, I can definitely help you with that. To generate effective prompts for your LLM-powered agent, we can start by brainstorming some common scenarios or topics that your partner may want to explore. For example, you could create prompts related to role playing, BDSM, or fantasies involving specific characters or scenarios. We can also incorporate your partner's feedback and preferences into the prompts to ensure that the agent is providing relevant and personalized suggestions. Let's work together to create a list of prompts that will help your partner explore her fantasies in a fun and engaging way.\n"
     ]
    }
   ],
   "source": [
    "print(conversation.run(input=\"Yes, all that sounds good. I'd like to use an LLM to generate the agent's responses. I think i need most help is with the prompts to use. Can you help me with that?\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadTimeout",
     "evalue": "The read operation timed out",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\httpcore\\_exceptions.py:10\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[1;34m(map)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 10\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:  \u001b[39m# noqa: PIE786\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\httpcore\\backends\\sync.py:28\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39msettimeout(timeout)\n\u001b[1;32m---> 28\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv(max_bytes)\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\ssl.py:1259\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1256\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1257\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1258\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1259\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(buflen)\n\u001b[0;32m   1260\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\ssl.py:1132\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m)\n\u001b[0;32m   1133\u001b[0m \u001b[39mexcept\u001b[39;00m SSLError \u001b[39mas\u001b[39;00m x:\n",
      "\u001b[1;31mTimeoutError\u001b[0m: The read operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\httpx\\_transports\\default.py:60\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 60\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:  \u001b[39m# noqa: PIE-786\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\httpx\\_transports\\default.py:218\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 218\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49mhandle_request(req)\n\u001b[0;32m    220\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:253\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresponse_closed(status)\n\u001b[1;32m--> 253\u001b[0m     \u001b[39mraise\u001b[39;00m exc\n\u001b[0;32m    254\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\httpcore\\_sync\\connection_pool.py:237\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[0;32m    238\u001b[0m \u001b[39mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    239\u001b[0m     \u001b[39m# The ConnectionNotAvailable exception is a special case, that\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[39m# indicates we need to retry the request on a new connection.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[39m# might end up as an HTTP/2 connection, but which actually ends\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[39m# up as HTTP/1.1.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\httpcore\\_sync\\connection.py:90\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[39mraise\u001b[39;00m ConnectionNotAvailable()\n\u001b[1;32m---> 90\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connection\u001b[39m.\u001b[39;49mhandle_request(request)\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\httpcore\\_sync\\http11.py:112\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_closed()\n\u001b[1;32m--> 112\u001b[0m \u001b[39mraise\u001b[39;00m exc\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\httpcore\\_sync\\http11.py:91\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[39mwith\u001b[39;00m Trace(\n\u001b[0;32m     84\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mhttp11.receive_response_headers\u001b[39m\u001b[39m\"\u001b[39m, request, kwargs\n\u001b[0;32m     85\u001b[0m ) \u001b[39mas\u001b[39;00m trace:\n\u001b[0;32m     86\u001b[0m     (\n\u001b[0;32m     87\u001b[0m         http_version,\n\u001b[0;32m     88\u001b[0m         status,\n\u001b[0;32m     89\u001b[0m         reason_phrase,\n\u001b[0;32m     90\u001b[0m         headers,\n\u001b[1;32m---> 91\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_receive_response_headers(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     92\u001b[0m     trace\u001b[39m.\u001b[39mreturn_value \u001b[39m=\u001b[39m (\n\u001b[0;32m     93\u001b[0m         http_version,\n\u001b[0;32m     94\u001b[0m         status,\n\u001b[0;32m     95\u001b[0m         reason_phrase,\n\u001b[0;32m     96\u001b[0m         headers,\n\u001b[0;32m     97\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\httpcore\\_sync\\http11.py:155\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     event \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_receive_event(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    156\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(event, h11\u001b[39m.\u001b[39mResponse):\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\httpcore\\_sync\\http11.py:191\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[39mif\u001b[39;00m event \u001b[39mis\u001b[39;00m h11\u001b[39m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 191\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_network_stream\u001b[39m.\u001b[39;49mread(\n\u001b[0;32m    192\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mREAD_NUM_BYTES, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[0;32m    193\u001b[0m     )\n\u001b[0;32m    195\u001b[0m     \u001b[39m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     \u001b[39m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[39m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[39m# it as a ConnectError.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\httpcore\\backends\\sync.py:26\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m     25\u001b[0m exc_map: ExceptionMapping \u001b[39m=\u001b[39m {socket\u001b[39m.\u001b[39mtimeout: ReadTimeout, \u001b[39mOSError\u001b[39;00m: ReadError}\n\u001b[1;32m---> 26\u001b[0m \u001b[39mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m     27\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39msettimeout(timeout)\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen\u001b[39m.\u001b[39;49mthrow(typ, value, traceback)\n\u001b[0;32m    154\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m    155\u001b[0m     \u001b[39m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[39m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[39m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\httpcore\\_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[1;34m(map)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(exc, from_exc):\n\u001b[1;32m---> 14\u001b[0m         \u001b[39mraise\u001b[39;00m to_exc(exc)\n\u001b[0;32m     15\u001b[0m \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mReadTimeout\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(conversation\u001b[39m.\u001b[39;49mrun(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mThat sounds great. Let\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39ms start with something simple. She is bisexual, and into gender nonconforming people sometimes. She likes to feel safe and cared for, but at the same time free to explore her sexuality her own way. \u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\langchain\\chains\\base.py:239\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, *args, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(args[\u001b[39m0\u001b[39m], callbacks\u001b[39m=\u001b[39mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m--> 239\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks)[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_keys[\u001b[39m0\u001b[39m]]\n\u001b[0;32m    241\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    242\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    243\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    244\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m but none were provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    245\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\langchain\\chains\\base.py:123\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[0;32m    107\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    108\u001b[0m     inputs: Union[Dict[\u001b[39mstr\u001b[39m, Any], Any],\n\u001b[0;32m    109\u001b[0m     return_only_outputs: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    110\u001b[0m     callbacks: Callbacks \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    111\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[0;32m    112\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Run the logic of this chain and add to output if desired.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \n\u001b[0;32m    114\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    121\u001b[0m \n\u001b[0;32m    122\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprep_inputs(inputs)\n\u001b[0;32m    124\u001b[0m     callback_manager \u001b[39m=\u001b[39m CallbackManager\u001b[39m.\u001b[39mconfigure(\n\u001b[0;32m    125\u001b[0m         callbacks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose\n\u001b[0;32m    126\u001b[0m     )\n\u001b[0;32m    127\u001b[0m     new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\langchain\\chains\\base.py:214\u001b[0m, in \u001b[0;36mChain.prep_inputs\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    212\u001b[0m     inputs \u001b[39m=\u001b[39m {\u001b[39mlist\u001b[39m(_input_keys)[\u001b[39m0\u001b[39m]: inputs}\n\u001b[0;32m    213\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 214\u001b[0m     external_context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmemory\u001b[39m.\u001b[39;49mload_memory_variables(inputs)\n\u001b[0;32m    215\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mexternal_context)\n\u001b[0;32m    216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_inputs(inputs)\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\langchain\\memory\\buffer.py:39\u001b[0m, in \u001b[0;36mConversationBufferMemory.load_memory_variables\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_memory_variables\u001b[39m(\u001b[39mself\u001b[39m, inputs: Dict[\u001b[39mstr\u001b[39m, Any]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[0;32m     38\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return history buffer.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory_key: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuffer}\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\langchain\\memory\\buffer.py:24\u001b[0m, in \u001b[0;36mConversationBufferMemory.buffer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchat_memory\u001b[39m.\u001b[39mmessages\n\u001b[0;32m     22\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     23\u001b[0m     \u001b[39mreturn\u001b[39;00m get_buffer_string(\n\u001b[1;32m---> 24\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_memory\u001b[39m.\u001b[39;49mmessages,\n\u001b[0;32m     25\u001b[0m         human_prefix\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhuman_prefix,\n\u001b[0;32m     26\u001b[0m         ai_prefix\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mai_prefix,\n\u001b[0;32m     27\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\langchain\\memory\\chat_message_histories\\zep.py:69\u001b[0m, in \u001b[0;36mZepChatMessageHistory.messages\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m     67\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmessages\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[BaseMessage]:  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Retrieve messages from Zep memory\"\"\"\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     zep_memory: Optional[Memory] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_memory()\n\u001b[0;32m     70\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m zep_memory:\n\u001b[0;32m     71\u001b[0m         \u001b[39mreturn\u001b[39;00m []\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\langchain\\memory\\chat_message_histories\\zep.py:111\u001b[0m, in \u001b[0;36mZepChatMessageHistory._get_memory\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mzep_python\u001b[39;00m \u001b[39mimport\u001b[39;00m NotFoundError\n\u001b[0;32m    110\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m     zep_memory: Memory \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mzep_client\u001b[39m.\u001b[39;49mget_memory(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msession_id)\n\u001b[0;32m    112\u001b[0m \u001b[39mexcept\u001b[39;00m NotFoundError:\n\u001b[0;32m    113\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    114\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSession \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession_id\u001b[39m}\u001b[39;00m\u001b[39m not found in Zep. Returning None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    115\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\zep_python\\zep_client.py:138\u001b[0m, in \u001b[0;36mZepClient.get_memory\u001b[1;34m(self, session_id, lastn)\u001b[0m\n\u001b[0;32m    136\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/sessions/\u001b[39m\u001b[39m{\u001b[39;00msession_id\u001b[39m}\u001b[39;00m\u001b[39m/memory\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gen_get_params(lastn)\n\u001b[1;32m--> 138\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mget(url, params\u001b[39m=\u001b[39;49mparams)\n\u001b[0;32m    140\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m404\u001b[39m:\n\u001b[0;32m    141\u001b[0m     \u001b[39mraise\u001b[39;00m NotFoundError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo memory found for session \u001b[39m\u001b[39m{\u001b[39;00msession_id\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\httpx\\_client.py:1041\u001b[0m, in \u001b[0;36mClient.get\u001b[1;34m(self, url, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\n\u001b[0;32m   1025\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1026\u001b[0m     url: URLTypes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1034\u001b[0m     extensions: typing\u001b[39m.\u001b[39mOptional[RequestExtensions] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1035\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Response:\n\u001b[0;32m   1036\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[39m    Send a `GET` request.\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \n\u001b[0;32m   1039\u001b[0m \u001b[39m    **Parameters**: See `httpx.request`.\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1041\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m   1042\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1043\u001b[0m         url,\n\u001b[0;32m   1044\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m   1045\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m   1046\u001b[0m         cookies\u001b[39m=\u001b[39;49mcookies,\n\u001b[0;32m   1047\u001b[0m         auth\u001b[39m=\u001b[39;49mauth,\n\u001b[0;32m   1048\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[0;32m   1049\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m   1050\u001b[0m         extensions\u001b[39m=\u001b[39;49mextensions,\n\u001b[0;32m   1051\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\httpx\\_client.py:814\u001b[0m, in \u001b[0;36mClient.request\u001b[1;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[0;32m    799\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(message, \u001b[39mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m    801\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_request(\n\u001b[0;32m    802\u001b[0m     method\u001b[39m=\u001b[39mmethod,\n\u001b[0;32m    803\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    812\u001b[0m     extensions\u001b[39m=\u001b[39mextensions,\n\u001b[0;32m    813\u001b[0m )\n\u001b[1;32m--> 814\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(request, auth\u001b[39m=\u001b[39;49mauth, follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects)\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\httpx\\_client.py:901\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    893\u001b[0m follow_redirects \u001b[39m=\u001b[39m (\n\u001b[0;32m    894\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfollow_redirects\n\u001b[0;32m    895\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[0;32m    896\u001b[0m     \u001b[39melse\u001b[39;00m follow_redirects\n\u001b[0;32m    897\u001b[0m )\n\u001b[0;32m    899\u001b[0m auth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 901\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_auth(\n\u001b[0;32m    902\u001b[0m     request,\n\u001b[0;32m    903\u001b[0m     auth\u001b[39m=\u001b[39;49mauth,\n\u001b[0;32m    904\u001b[0m     follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[0;32m    905\u001b[0m     history\u001b[39m=\u001b[39;49m[],\n\u001b[0;32m    906\u001b[0m )\n\u001b[0;32m    907\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    908\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\httpx\\_client.py:929\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    926\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(auth_flow)\n\u001b[0;32m    928\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 929\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_handling_redirects(\n\u001b[0;32m    930\u001b[0m         request,\n\u001b[0;32m    931\u001b[0m         follow_redirects\u001b[39m=\u001b[39;49mfollow_redirects,\n\u001b[0;32m    932\u001b[0m         history\u001b[39m=\u001b[39;49mhistory,\n\u001b[0;32m    933\u001b[0m     )\n\u001b[0;32m    934\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    935\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\httpx\\_client.py:966\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    963\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mrequest\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    964\u001b[0m     hook(request)\n\u001b[1;32m--> 966\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_single_request(request)\n\u001b[0;32m    967\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    968\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_event_hooks[\u001b[39m\"\u001b[39m\u001b[39mresponse\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\httpx\\_client.py:1002\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    997\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    998\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    999\u001b[0m     )\n\u001b[0;32m   1001\u001b[0m \u001b[39mwith\u001b[39;00m request_context(request\u001b[39m=\u001b[39mrequest):\n\u001b[1;32m-> 1002\u001b[0m     response \u001b[39m=\u001b[39m transport\u001b[39m.\u001b[39;49mhandle_request(request)\n\u001b[0;32m   1004\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(response\u001b[39m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1006\u001b[0m response\u001b[39m.\u001b[39mrequest \u001b[39m=\u001b[39m request\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\httpx\\_transports\\default.py:217\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(request\u001b[39m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m    205\u001b[0m req \u001b[39m=\u001b[39m httpcore\u001b[39m.\u001b[39mRequest(\n\u001b[0;32m    206\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[0;32m    207\u001b[0m     url\u001b[39m=\u001b[39mhttpcore\u001b[39m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    215\u001b[0m     extensions\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mextensions,\n\u001b[0;32m    216\u001b[0m )\n\u001b[1;32m--> 217\u001b[0m \u001b[39mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m    218\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool\u001b[39m.\u001b[39mhandle_request(req)\n\u001b[0;32m    220\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(resp\u001b[39m.\u001b[39mstream, typing\u001b[39m.\u001b[39mIterable)\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\contextlib.py:153\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    151\u001b[0m     value \u001b[39m=\u001b[39m typ()\n\u001b[0;32m    152\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen\u001b[39m.\u001b[39;49mthrow(typ, value, traceback)\n\u001b[0;32m    154\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m    155\u001b[0m     \u001b[39m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     \u001b[39m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[39m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[39mreturn\u001b[39;00m exc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\jayfd\\anaconda3\\envs\\family-gpt\\lib\\site-packages\\httpx\\_transports\\default.py:77\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[0;32m     76\u001b[0m message \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(exc)\n\u001b[1;32m---> 77\u001b[0m \u001b[39mraise\u001b[39;00m mapped_exc(message) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[1;31mReadTimeout\u001b[0m: The read operation timed out"
     ]
    }
   ],
   "source": [
    "print(conversation.run(input=\"That sounds great. Let's start with something simple. She is bisexual, and into gender nonconforming people sometimes. She likes to feel safe and cared for, but at the same time free to explore her sexuality her own way. \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conversation.run(input=\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conversation.run(input=\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(conversation.run(input=\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = \"\"\"Assistant is a large language model trained by OpenAI.\n",
    "\n",
    "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
    "\n",
    "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
    "\n",
    "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
    "\n",
    "TOOLS:\n",
    "------\n",
    "\n",
    "Assistant has access to the following tools:\"\"\"\n",
    "FORMAT_INSTRUCTIONS = \"\"\"To use a tool, please use the following format:\n",
    "\n",
    "```\n",
    "Thought: Do I need to use a tool? Yes\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "```\n",
    "\n",
    "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
    "\n",
    "```\n",
    "Thought: Do I need to use a tool? No\n",
    "{ai_prefix}: [your response here]\n",
    "```\"\"\"\n",
    "\n",
    "SUFFIX = \"\"\"Begin!\n",
    "\n",
    "Previous conversation history:\n",
    "{chat_history}\n",
    "\n",
    "New input: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
